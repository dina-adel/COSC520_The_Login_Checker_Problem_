{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSC 520 - Assignment 1: The Login Checker Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xe7970',\n",
       " 'a6ocua',\n",
       " 'mb89dl',\n",
       " 'casfez',\n",
       " 'jkryo1',\n",
       " 'ntww5b',\n",
       " 'fivest',\n",
       " 'oozral',\n",
       " 'z451jk',\n",
       " '961x3r']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_logins(n, length=6):\n",
    "    \"\"\"Generates a list of n random logins.\n",
    "        - n: number of logins to generate\n",
    "        - length: length of each login (default is 6)\n",
    "        Returns a list of unique logins.\n",
    "    \"\"\"\n",
    "    logins = set()\n",
    "    while len(logins) < n:\n",
    "        login = ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "        logins.add(login)\n",
    "    return list(logins)\n",
    "\n",
    "generate_logins(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyprobables in c:\\users\\staro\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "#%!pip install pybloom_live\n",
    "#%!pip install cuckoofilter\n",
    "#%pip install pyprobables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file named \"login_all_1B.txt\" was created with 1B unique usernames (Drive Link: {https://drive.google.com/file/d/1Yl8NTkzK7QA1cl4inRCTQPCEDcJB22U-/view?usp=sharing}). \n",
    "\n",
    "The generation script is added to this repo. \n",
    "\n",
    "Later, I will define the functions I will use for loading the data as well as comparing the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import bisect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pybloom_live import BloomFilter\n",
    "from probables import CuckooFilter  \n",
    "import json\n",
    "import tracemalloc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logins(filename, num_logins):\n",
    "    \"\"\"Reads the first 'num_logins' from the specified file.\n",
    "        - filename: path to the file containing logins (one per line)\n",
    "        - num_logins: number of logins to read from the file\n",
    "        Returns a list of logins.\n",
    "    \"\"\"\n",
    "    logins = []\n",
    "    print(f\"  Reading {num_logins} logins from {filename}...\")\n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= num_logins:\n",
    "                    break\n",
    "                logins.append(line.strip())\n",
    "        if len(logins) < num_logins:\n",
    "            print(f\"  Warning: File contains only {len(logins)} logins, less than requested {num_logins}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  Error: The file '{filename}' was not found.\")\n",
    "        return []\n",
    "    return logins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage_mb():\n",
    "    \"\"\"Return current memory usage in MB using tracemalloc\n",
    "    \"\"\"\n",
    "    current, peak = tracemalloc.get_traced_memory()\n",
    "    return current / (1024*1024), peak / (1024*1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance(n_values, filename):\n",
    "    \"\"\"Compares performance of different login checkers.\n",
    "        - n_values: list of n values (number of logins) to test\n",
    "        - filename: path to the file containing logins (one per line)\n",
    "                \n",
    "        Methods compared:\n",
    "        - Linear Search\n",
    "        - Binary Search\n",
    "        - Hashing (Set)\n",
    "        - Bloom Filter\n",
    "        - Cuckoo Filter\n",
    "        \n",
    "        1. Build Phase: Time and memory to build the data structure.\n",
    "        2. Lookup Phase: Average time to lookup a login (averaged over multiple lookups).\n",
    "        3. Memory Usage: Memory used by the data structure after building.\n",
    "        \n",
    "        Returns:\n",
    "        - build_results: dict mapping method names to list of build times\n",
    "        - lookup_results: dict mapping method names to list of average lookup times\n",
    "        - memory_results: dict mapping method names to list of memory usage in MB\n",
    "    \"\"\"\n",
    "    \n",
    "    build_results = {}\n",
    "    lookup_results = {}\n",
    "    memory_results = {}\n",
    "\n",
    "    methods = [\"Linear Search\", \"Binary Search\", \"Hashing (Set)\", \"Bloom Filter\", \"Cuckoo Filter\"]\n",
    "    for m in methods:\n",
    "        build_results[m] = []\n",
    "        lookup_results[m] = []\n",
    "        memory_results[m] = []\n",
    "\n",
    "    num_lookups = 1000 # Number of lookups to average over\n",
    "    \n",
    "    # load logins from the file\n",
    "    for n in n_values: \n",
    "        print(f\"\\nRunning performance tests for n = {n}...\")\n",
    "        logins = load_logins(filename, n)\n",
    "        if not logins or len(logins) < n:\n",
    "            for m in methods:\n",
    "                build_results[m].append(0)\n",
    "                lookup_results[m].append(0)\n",
    "                memory_results[m].append(0)\n",
    "            continue\n",
    "\n",
    "        test_login_exists = logins[-1]\n",
    "\n",
    "        tracemalloc.start()\n",
    "\n",
    "        # --- Linear Search ---\n",
    "        print(\"  Building Linear Search...\")\n",
    "        start_mem = memory_usage_mb()[0]\n",
    "        start_time = time.time()\n",
    "        linear_list = list(logins)\n",
    "        build_results[\"Linear Search\"].append(time.time() - start_time)\n",
    "        memory_results[\"Linear Search\"].append(memory_usage_mb()[0] - start_mem)\n",
    "\n",
    "        # --- Binary Search ---\n",
    "        print(\"  Building Binary Search...\")\n",
    "        start_mem = memory_usage_mb()[0]\n",
    "        start_time = time.time()\n",
    "        sorted_logins = sorted(logins)\n",
    "        build_results[\"Binary Search\"].append(time.time() - start_time)\n",
    "        memory_results[\"Binary Search\"].append(memory_usage_mb()[0] - start_mem)\n",
    "\n",
    "        # --- Hashing (Set) ---\n",
    "        print(\"  Building Hashing (Set)...\")\n",
    "        start_mem = memory_usage_mb()[0]\n",
    "        start_time = time.time()\n",
    "        login_set = set(logins)\n",
    "        build_results[\"Hashing (Set)\"].append(time.time() - start_time)\n",
    "        memory_results[\"Hashing (Set)\"].append(memory_usage_mb()[0] - start_mem)\n",
    "\n",
    "        # --- Bloom Filter ---\n",
    "        print(\"  Building Bloom Filter...\")\n",
    "        start_mem = memory_usage_mb()[0]\n",
    "        start_time = time.time()\n",
    "        bloom = BloomFilter(capacity=n, error_rate=0.001)\n",
    "        for login in logins:\n",
    "            bloom.add(login)\n",
    "        build_results[\"Bloom Filter\"].append(time.time() - start_time)\n",
    "        memory_results[\"Bloom Filter\"].append(memory_usage_mb()[0] - start_mem)\n",
    "\n",
    "        # --- Cuckoo Filter ---\n",
    "        print(\"  Building Cuckoo Filter...\")\n",
    "        start_mem = memory_usage_mb()[0]\n",
    "        start_time = time.time()\n",
    "        cuckoo = CuckooFilter(capacity=n, bucket_size=4, finger_size=2)\n",
    "        inserted_count = 0\n",
    "        try:    # error handling for cuckoo filter full condition\n",
    "            cuckoo.add(login)\n",
    "            inserted_count += 1\n",
    "        except Exception:\n",
    "            print(f\"Cuckoo filter became full after {inserted_count} insertions.\")\n",
    "            break\n",
    "        build_results[\"Cuckoo Filter\"].append(time.time() - start_time)\n",
    "        memory_results[\"Cuckoo Filter\"].append(memory_usage_mb()[0] - start_mem)\n",
    "        del logins\n",
    "\n",
    "        # --- Lookup Phase ---\n",
    "        print(\"  Timing Linear Search lookups...\")\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_lookups):\n",
    "            _ = test_login_exists in linear_list\n",
    "        lookup_results[\"Linear Search\"].append((time.time() - start_time)/num_lookups)\n",
    "        del linear_list\n",
    "\n",
    "        print(\"  Timing Binary Search lookups...\")\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_lookups):\n",
    "            index = bisect.bisect_left(sorted_logins, test_login_exists)\n",
    "            _ = index < len(sorted_logins) and sorted_logins[index] == test_login_exists\n",
    "        lookup_results[\"Binary Search\"].append((time.time() - start_time)/num_lookups)\n",
    "        del sorted_logins\n",
    "\n",
    "        print(\"  Timing Hashing (Set) lookups...\")\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_lookups):\n",
    "            _ = test_login_exists in login_set\n",
    "        lookup_results[\"Hashing (Set)\"].append((time.time() - start_time)/num_lookups)\n",
    "        del login_set\n",
    "\n",
    "        print(\"  Timing Bloom Filter lookups...\")\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_lookups):\n",
    "            _ = test_login_exists in bloom\n",
    "        lookup_results[\"Bloom Filter\"].append((time.time() - start_time)/num_lookups)\n",
    "        del bloom\n",
    "\n",
    "        print(\"  Timing Cuckoo Filter lookups...\")\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_lookups):\n",
    "            _ = cuckoo.check(test_login_exists)\n",
    "        lookup_results[\"Cuckoo Filter\"].append((time.time() - start_time)/num_lookups)\n",
    "        del cuckoo\n",
    "\n",
    "        tracemalloc.stop()\n",
    "\n",
    "    return build_results, lookup_results, memory_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_results(n_values, build_data, lookup_data, memory_data):\n",
    "    \"\"\"Plots bar charts for build times, lookup times, and memory usage.\n",
    "        - n_values: list of n values (number of logins)\n",
    "        - build_data: dict mapping method names to list of build times\n",
    "        - lookup_data: dict mapping method names to list of average lookup times\n",
    "        - memory_data: dict mapping method names to list of memory usage in MB\n",
    "        Plots and saves the charts as PNG files.\n",
    "    \"\"\"\n",
    "    methods = list(build_data.keys())\n",
    "    x = np.arange(len(n_values))\n",
    "    width = 0.15\n",
    "\n",
    "    # Build Times\n",
    "    fig1, ax1 = plt.subplots(figsize=(14, 7))\n",
    "    for i, method in enumerate(methods):\n",
    "        valid_data = [d for d in build_data[method] if d > 0]\n",
    "        valid_x = [pos for pos, d in zip(x, build_data[method]) if d > 0]\n",
    "        if not valid_data: continue\n",
    "        offset = width * (i - len(methods)/2) + width/2\n",
    "        rects = ax1.bar(np.array(valid_x)+offset, valid_data, width, label=method)\n",
    "        ax1.bar_label(rects, padding=3, rotation=90, fmt=\"%.2e\")\n",
    "    ax1.set_xlabel(\"Number of Logins (n)\")\n",
    "    ax1.set_ylabel(\"Build Time (s) - Log Scale\")\n",
    "    ax1.set_title(\"Data Structure Build Times\")\n",
    "    ax1.set_xticks(x, n_values)\n",
    "    ax1.set_yscale(\"log\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, which=\"both\", ls=\"--\", axis=\"y\")\n",
    "    fig1.tight_layout()\n",
    "    plt.savefig(\"build_times_barchart.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Lookup Times\n",
    "    fig2, ax2 = plt.subplots(figsize=(14, 7))\n",
    "    for i, method in enumerate(methods):\n",
    "        valid_data = [d for d in lookup_data[method] if d > 0]\n",
    "        valid_x = [pos for pos, d in zip(x, lookup_data[method]) if d > 0]\n",
    "        if not valid_data: continue\n",
    "        offset = width * (i - len(methods)/2) + width/2\n",
    "        rects = ax2.bar(np.array(valid_x)+offset, valid_data, width, label=method)\n",
    "        ax2.bar_label(rects, padding=3, rotation=90, fmt=\"%.2e\")\n",
    "    ax2.set_xlabel(\"Number of Logins (n)\")\n",
    "    ax2.set_ylabel(\"Average Lookup Time (s) - Log Scale\")\n",
    "    ax2.set_title(\"Login Checker Lookup Times\")\n",
    "    ax2.set_xticks(x, n_values)\n",
    "    ax2.set_yscale(\"log\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, which=\"both\", ls=\"--\", axis=\"y\")\n",
    "    fig2.tight_layout()\n",
    "    plt.savefig(\"lookup_times_barchart.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Memory Usage\n",
    "    fig3, ax3 = plt.subplots(figsize=(14, 7))\n",
    "    for i, method in enumerate(methods):\n",
    "        valid_data = [d for d in memory_data[method] if d > 0]\n",
    "        valid_x = [pos for pos, d in zip(x, memory_data[method]) if d > 0]\n",
    "        if not valid_data: continue\n",
    "        offset = width * (i - len(methods)/2) + width/2\n",
    "        rects = ax3.bar(np.array(valid_x)+offset, valid_data, width, label=method)\n",
    "        ax3.bar_label(rects, padding=3, rotation=90, fmt=\"%.2f MB\")\n",
    "    ax3.set_xlabel(\"Number of Logins (n)\")\n",
    "    ax3.set_ylabel(\"Memory Usage (MB)\")\n",
    "    ax3.set_title(\"Memory Usage per Data Structure\")\n",
    "    ax3.set_xticks(x, n_values)\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, ls=\"--\", axis=\"y\")\n",
    "    fig3.tight_layout()\n",
    "    plt.savefig(\"memory_usage_barchart.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_memory_usage_line(n_values, memory_data):\n",
    "    \"\"\"\n",
    "    Plots only the memory usage results as a line plot.\n",
    "    Args:\n",
    "        n_values (list): A list of the number of items tested (e.g., [1_000_000, 5_000_000]).\n",
    "        memory_data (dict): A dictionary containing memory usage results for each method.\n",
    "    \"\"\"\n",
    "    methods = list(memory_data.keys())\n",
    "    \n",
    "    # Convert n_values to millions for a cleaner x-axis\n",
    "    n_values_in_millions = [n / 1_000_000 for n in n_values]\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    for method in methods:\n",
    "        # Plot a line for each method with markers on the data points\n",
    "        plt.plot(n_values_in_millions, memory_data[method], marker='o', linestyle='-', label=method)\n",
    "\n",
    "    # Add text, title, and labels\n",
    "    plt.xlabel(\"Number of Logins (in millions)\")\n",
    "    plt.ylabel(\"Memory Usage (MB)\")\n",
    "    plt.title(\"Memory Usage per Data Structure\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"memory_usage_lineplot.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line_results(n_values, build_data, lookup_data, build_filename, lookup_filename, use_log_scale=True, exclude=None):\n",
    "    \"\"\" Generates line plot files for build and lookup times\n",
    "        - n_values: list of n values (number of logins)\n",
    "        - build_data: dict mapping method names to list of build times\n",
    "        - lookup_data: dict mapping method names to list of average lookup times\n",
    "        - build_filename: filename to save the build times plot\n",
    "        - lookup_filename: filename to save the lookup times plot\n",
    "        - use_log_scale: whether to use a logarithmic scale for the y-axis\n",
    "        - exclude: list of method names to exclude from the plots\n",
    "        Saves the plots as PNG files.\n",
    "    \"\"\"\n",
    "    if exclude is None:\n",
    "        exclude = []\n",
    "    \n",
    "    # Convert n_values to millions for the x-axis\n",
    "    n_values_in_millions = [n / 1_000_000 for n in n_values]\n",
    "    \n",
    "    methods_to_plot = [m for m in build_data.keys() if m not in exclude]\n",
    "    scale_type = \"Log\" if use_log_scale else \"Linear\"\n",
    "    excluded_str = f\"(Excluding: {', '.join(exclude)})\" if exclude else \"\"\n",
    "    \n",
    "    # --- Plot 1: Build Times ---\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for method in methods_to_plot:\n",
    "        # Use the converted x-axis values\n",
    "        plt.plot(n_values_in_millions, build_data[method], marker='o', linestyle='-', label=method)\n",
    "    \n",
    "    # Update the x-axis label\n",
    "    plt.xlabel(\"Number of Logins (in millions)\", fontsize=12)\n",
    "    plt.ylabel(\"Time (seconds)\", fontsize=12)\n",
    "    plt.title(f\"Build Times ({scale_type} Scale) {excluded_str}\", fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle='--', linewidth=0.5)\n",
    "    \n",
    "    if use_log_scale:\n",
    "        plt.yscale('log')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(build_filename)\n",
    "    plt.close()\n",
    "    print(f\"Plot saved as {build_filename}\")\n",
    "\n",
    "    # --- Plot 2: Lookup Times ---\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for method in methods_to_plot:\n",
    "        # Use the converted x-axis values\n",
    "        plt.plot(n_values_in_millions, lookup_data[method], marker='s', linestyle='-', label=method)\n",
    "\n",
    "    # Update the x-axis label\n",
    "    plt.xlabel(\"Number of Logins (in millions)\", fontsize=12)\n",
    "    plt.ylabel(\"Time (seconds)\", fontsize=12)\n",
    "    plt.title(f\"Lookup Times ({scale_type} Scale) {excluded_str}\", fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle='--', linewidth=0.5)\n",
    "\n",
    "    if use_log_scale:\n",
    "        plt.yscale('log')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(lookup_filename)\n",
    "    plt.close()\n",
    "    print(f\"Plot saved as {lookup_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_file = \"logins_all_1B.txt\"\n",
    "n_values_to_test = [1_000_000, 5_000_000, 10_000_000, 50_000_000]\n",
    "build_times, lookup_times, memory_usage = compare_performance(n_values_to_test, login_file)\n",
    "plot_bar_results(n_values_to_test, build_times, lookup_times, memory_usage)\n",
    "plot_memory_usage_line(n_values_to_test, memory_usage)\n",
    "plot_line_results(\n",
    "    n_values_to_test, build_times, lookup_times,\n",
    "    build_filename=\"build_times_log_scale.png\",\n",
    "    lookup_filename=\"lookup_times_log_scale.png\",\n",
    "    use_log_scale=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to performance_results.json\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save results to JSON file\"\"\"\n",
    "all_results = {\n",
    "    'build_times': build_times,\n",
    "    'lookup_times': lookup_times,\n",
    "    'memory_usage': memory_usage\n",
    "}\n",
    "\n",
    "with open(\"performance_results.json\", \"w\") as f:\n",
    "    json.dump(all_results, f, indent=4)\n",
    "\n",
    "print(\"✅ Results saved to performance_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.025s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2186ea3c210>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import bisect\n",
    "from pybloom_live import BloomFilter\n",
    "from probables import CuckooFilter\n",
    "\n",
    "class TestLoginCheckers(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    A comprehensive suite of unit tests for all login checker methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Set up common data for the tests. This method is run before each test.\n",
    "        \"\"\"\n",
    "        self.logins = [\"user1\", \"test_user\", \"admin\", \"guest\", \"dina579\"]\n",
    "        self.login_exists = \"admin\"\n",
    "        self.login_does_not_exist = \"unknown_user\"\n",
    "\n",
    "    def test_linear_search(self):\n",
    "        \"\"\"\n",
    "        Tests the linear search method (using a list).\n",
    "        \"\"\"\n",
    "        linear_list = self.logins\n",
    "        self.assertTrue(self.login_exists in linear_list)\n",
    "        self.assertFalse(self.login_does_not_exist in linear_list)\n",
    "\n",
    "    def test_binary_search(self):\n",
    "        \"\"\"\n",
    "        Tests the binary search method on a sorted list.\n",
    "        \"\"\"\n",
    "        sorted_logins = sorted(self.logins)\n",
    "        \n",
    "        # Test for an existing login\n",
    "        index_exists = bisect.bisect_left(sorted_logins, self.login_exists)\n",
    "        found_exists = (index_exists < len(sorted_logins) and \n",
    "                        sorted_logins[index_exists] == self.login_exists)\n",
    "        self.assertTrue(found_exists)\n",
    "\n",
    "        # Test for a non-existent login\n",
    "        index_not_exists = bisect.bisect_left(sorted_logins, self.login_does_not_exist)\n",
    "        found_not_exists = (index_not_exists < len(sorted_logins) and \n",
    "                            sorted_logins[index_not_exists] == self.login_does_not_exist)\n",
    "        self.assertFalse(found_not_exists)\n",
    "\n",
    "    def test_hashing_set(self):\n",
    "        \"\"\"\n",
    "        Tests the hashing method (using a set).\n",
    "        \"\"\"\n",
    "        login_set = set(self.logins)\n",
    "        self.assertTrue(self.login_exists in login_set)\n",
    "        self.assertFalse(self.login_does_not_exist in login_set)\n",
    "    \n",
    "    def test_bloom_filter(self):\n",
    "        \"\"\"\n",
    "        Tests the basic functionality of the Bloom Filter.\n",
    "        \"\"\"\n",
    "        bloom = BloomFilter(capacity=100, error_rate=0.01)\n",
    "        self.assertFalse('test' in bloom)\n",
    "        bloom.add('test')\n",
    "        self.assertTrue('test' in bloom)\n",
    "        \n",
    "    def test_cuckoo_filter(self):\n",
    "        \"\"\"\n",
    "        Tests the basic functionality of the Cuckoo Filter, including deletion.\n",
    "        \"\"\"\n",
    "        cuckoo = CuckooFilter(capacity=100)\n",
    "        self.assertFalse(cuckoo.check('test'))\n",
    "        cuckoo.add('test')\n",
    "        self.assertTrue(cuckoo.check('test'))\n",
    "        cuckoo.remove('test')\n",
    "        self.assertFalse(cuckoo.check('test'))\n",
    "\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
